{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from pathlib import Path \n",
    "import os\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT \n",
    "        changes to make and flow:\n",
    "        \n",
    "        --> traverse the folder in batches of 5: obtain 5 files\n",
    "        --> take the 5 files and convert them into a list of tuples and merge it all into 1 main list of tuples\n",
    "        --> take this merged data and push it to the db\n",
    "        --> on successful push delete the files from staged and copy them to archieve\n",
    "        --> think about maintaining a log of some kind as ChatGPT\n",
    "        --> repeat this process until the entire staged/Olympic_Athlete_Biography_Files is empty \n",
    "        --> learn how to perform the repeat and batch process the files into the db using airflow \n",
    "        --> Complete this for all tables and dags ensure to use truncate and append \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed parameters\n",
    "curr_dir = Path(os.getcwd())\n",
    "source_path = curr_dir / 'Data' / 'staged' / 'Olympic_Athlete_Biography_Files'\n",
    "destination_path = curr_dir / 'Data' / 'archieve' / 'Olympic_Athlete_Biography_Files_archieve'\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function turns a dataframe into a list of tuples\n",
    "def make_list_of_tuples(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.head(1)\n",
    "    data = list(df.itertuples(index=False, name=None))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the sorting key function \n",
    "def natural_key(filename):\n",
    "        return [int(part) if part.isdigit() else part.lower() for part in re.split(r'(\\d+)', filename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olympic_Athlete_Biography10.csv',\n",
       " 'Olympic_Athlete_Biography11.csv',\n",
       " 'Olympic_Athlete_Biography12.csv',\n",
       " 'Olympic_Athlete_Biography13.csv',\n",
       " 'Olympic_Athlete_Biography14.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this gives the names of the first 5 dir in the folder in sorted order \n",
    "dir_source = sorted(os.listdir(source_path), key=natural_key)[:batch_size]\n",
    "dir_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have a standard batch size of 5, we will simply pick the first 5 files based on natural_key and move them to archieve \n",
    "# i think this should be done instantly rather than in batches so after total_data = total_data + data we call the \n",
    "# handle_file_movement function, we will have the file path which is temp_file_path and we have the destination_path\n",
    "# okay so simply os.remove and shutil.copy will be done by handle_file_movement\n",
    "def handle_file_movement(file_path):\n",
    "    # lets move the file first \n",
    "    shutil.copy2(file_path, destination_path)\n",
    "    # then remove it from the original folder\n",
    "    os.remove(file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25976"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = []\n",
    "for file in range(len(dir_source)):\n",
    "    temp_file_path = str(source_path) + '/' + str(dir_source[file])\n",
    "    data = make_list_of_tuples(temp_file_path)\n",
    "    total_data = total_data + data\n",
    "    handle_file_movement(temp_file_path)\n",
    "    \n",
    "len(total_data)\n",
    "\n",
    "# above is the logic we will use in the main code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, so far we are able to retrieve files in batches of 5 and make a total_data which we will directly insert into the db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "\n",
    "--> As soon as the total_data is ready, move the 5 files to archieve and delete them from staged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
